{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T10:58:20.725875Z",
     "start_time": "2024-07-23T10:58:20.722237Z"
    }
   },
   "source": "words = open('names.txt', 'r').read().splitlines()",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T10:58:22.863748Z",
     "start_time": "2024-07-23T10:58:22.857013Z"
    }
   },
   "cell_type": "code",
   "source": "words",
   "id": "48b5e6a19407374d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn',\n",
       " 'abigail',\n",
       " 'emily',\n",
       " 'elizabeth',\n",
       " 'mila',\n",
       " 'ella',\n",
       " 'avery',\n",
       " 'sofia',\n",
       " 'camila',\n",
       " 'aria',\n",
       " 'scarlett',\n",
       " 'victoria',\n",
       " 'madison',\n",
       " 'luna',\n",
       " 'grace',\n",
       " 'chloe',\n",
       " 'penelope',\n",
       " 'layla',\n",
       " 'riley',\n",
       " 'zoey',\n",
       " 'nora',\n",
       " 'lily',\n",
       " 'eleanor',\n",
       " 'hannah',\n",
       " 'lillian',\n",
       " 'addison',\n",
       " 'aubrey',\n",
       " 'ellie',\n",
       " 'stella',\n",
       " 'natalie',\n",
       " 'zoe',\n",
       " 'leah',\n",
       " 'hazel',\n",
       " 'violet',\n",
       " 'aurora',\n",
       " 'savannah',\n",
       " 'audrey',\n",
       " 'brooklyn',\n",
       " 'bella',\n",
       " 'claire',\n",
       " 'skylar',\n",
       " 'lucy',\n",
       " 'paisley',\n",
       " 'everly',\n",
       " 'anna',\n",
       " 'caroline',\n",
       " 'nova',\n",
       " 'genesis',\n",
       " 'emilia',\n",
       " 'kennedy',\n",
       " 'samantha',\n",
       " 'maya',\n",
       " 'willow',\n",
       " 'kinsley',\n",
       " 'naomi',\n",
       " 'aaliyah',\n",
       " 'elena',\n",
       " 'sarah',\n",
       " 'ariana',\n",
       " 'allison',\n",
       " 'gabriella',\n",
       " 'alice',\n",
       " 'madelyn',\n",
       " 'cora',\n",
       " 'ruby',\n",
       " 'eva',\n",
       " 'serenity',\n",
       " 'autumn',\n",
       " 'adeline',\n",
       " 'hailey',\n",
       " 'gianna',\n",
       " 'valentina',\n",
       " 'isla',\n",
       " 'eliana',\n",
       " 'quinn',\n",
       " 'nevaeh',\n",
       " 'ivy',\n",
       " 'sadie',\n",
       " 'piper',\n",
       " 'lydia',\n",
       " 'alexa',\n",
       " 'josephine',\n",
       " 'emery',\n",
       " 'julia',\n",
       " 'delilah',\n",
       " 'arianna',\n",
       " 'vivian',\n",
       " 'kaylee',\n",
       " 'sophie',\n",
       " 'brielle',\n",
       " 'madeline',\n",
       " 'peyton',\n",
       " 'rylee',\n",
       " 'clara',\n",
       " 'hadley',\n",
       " 'melanie',\n",
       " 'mackenzie',\n",
       " 'reagan',\n",
       " 'adalynn',\n",
       " 'liliana',\n",
       " 'aubree',\n",
       " 'jade',\n",
       " 'katherine',\n",
       " 'isabelle',\n",
       " 'natalia',\n",
       " 'raelynn',\n",
       " 'maria',\n",
       " 'athena',\n",
       " 'ximena',\n",
       " 'arya',\n",
       " 'leilani',\n",
       " 'taylor',\n",
       " 'faith',\n",
       " 'rose',\n",
       " 'kylie',\n",
       " 'alexandra',\n",
       " 'mary',\n",
       " 'margaret',\n",
       " 'lyla',\n",
       " 'ashley',\n",
       " 'amaya',\n",
       " 'eliza',\n",
       " 'brianna',\n",
       " 'bailey',\n",
       " 'andrea',\n",
       " 'khloe',\n",
       " 'jasmine',\n",
       " 'melody',\n",
       " 'iris',\n",
       " 'isabel',\n",
       " 'norah',\n",
       " 'annabelle',\n",
       " 'valeria',\n",
       " 'emerson',\n",
       " 'adalyn',\n",
       " 'ryleigh',\n",
       " 'eden',\n",
       " 'emersyn',\n",
       " 'anastasia',\n",
       " 'kayla',\n",
       " 'alyssa',\n",
       " 'juliana',\n",
       " 'charlie',\n",
       " 'esther',\n",
       " 'ariel',\n",
       " 'cecilia',\n",
       " 'valerie',\n",
       " 'alina',\n",
       " 'molly',\n",
       " 'reese',\n",
       " 'aliyah',\n",
       " 'lilly',\n",
       " 'parker',\n",
       " 'finley',\n",
       " 'morgan',\n",
       " 'sydney',\n",
       " 'jordyn',\n",
       " 'eloise',\n",
       " 'trinity',\n",
       " 'daisy',\n",
       " 'kimberly',\n",
       " 'lauren',\n",
       " 'genevieve',\n",
       " 'sara',\n",
       " 'arabella',\n",
       " 'harmony',\n",
       " 'elise',\n",
       " 'remi',\n",
       " 'teagan',\n",
       " 'alexis',\n",
       " 'london',\n",
       " 'sloane',\n",
       " 'laila',\n",
       " 'lucia',\n",
       " 'diana',\n",
       " 'juliette',\n",
       " 'sienna',\n",
       " 'elliana',\n",
       " 'londyn',\n",
       " 'ayla',\n",
       " 'callie',\n",
       " 'gracie',\n",
       " 'josie',\n",
       " 'amara',\n",
       " 'jocelyn',\n",
       " 'daniela',\n",
       " 'everleigh',\n",
       " 'mya',\n",
       " 'rachel',\n",
       " 'summer',\n",
       " 'alana',\n",
       " 'brooke',\n",
       " 'alaina',\n",
       " 'mckenzie',\n",
       " 'catherine',\n",
       " 'amy',\n",
       " 'presley',\n",
       " 'journee',\n",
       " 'rosalie',\n",
       " 'ember',\n",
       " 'brynlee',\n",
       " 'rowan',\n",
       " 'joanna',\n",
       " 'paige',\n",
       " 'rebecca',\n",
       " 'ana',\n",
       " 'sawyer',\n",
       " 'mariah',\n",
       " 'nicole',\n",
       " 'brooklynn',\n",
       " 'payton',\n",
       " 'marley',\n",
       " 'fiona',\n",
       " 'georgia',\n",
       " 'lila',\n",
       " 'harley',\n",
       " 'adelyn',\n",
       " 'alivia',\n",
       " 'noelle',\n",
       " 'gemma',\n",
       " 'vanessa',\n",
       " 'journey',\n",
       " 'makayla',\n",
       " 'angelina',\n",
       " 'adaline',\n",
       " 'catalina',\n",
       " 'alayna',\n",
       " 'julianna',\n",
       " 'leila',\n",
       " 'lola',\n",
       " 'adriana',\n",
       " 'june',\n",
       " 'juliet',\n",
       " 'jayla',\n",
       " 'river',\n",
       " 'tessa',\n",
       " 'lia',\n",
       " 'dakota',\n",
       " 'delaney',\n",
       " 'selena',\n",
       " 'blakely',\n",
       " 'ada',\n",
       " 'camille',\n",
       " 'zara',\n",
       " 'malia',\n",
       " 'hope',\n",
       " 'samara',\n",
       " 'vera',\n",
       " 'mckenna',\n",
       " 'briella',\n",
       " 'izabella',\n",
       " 'hayden',\n",
       " 'raegan',\n",
       " 'michelle',\n",
       " 'angela',\n",
       " 'ruth',\n",
       " 'freya',\n",
       " 'kamila',\n",
       " 'vivienne',\n",
       " 'aspen',\n",
       " 'olive',\n",
       " 'kendall',\n",
       " 'elaina',\n",
       " 'thea',\n",
       " 'kali',\n",
       " 'destiny',\n",
       " 'amiyah',\n",
       " 'evangeline',\n",
       " 'cali',\n",
       " 'blake',\n",
       " 'elsie',\n",
       " 'juniper',\n",
       " 'alexandria',\n",
       " 'myla',\n",
       " 'ariella',\n",
       " 'kate',\n",
       " 'mariana',\n",
       " 'lilah',\n",
       " 'charlee',\n",
       " 'daleyza',\n",
       " 'nyla',\n",
       " 'jane',\n",
       " 'maggie',\n",
       " 'zuri',\n",
       " 'aniyah',\n",
       " 'lucille',\n",
       " 'leia',\n",
       " 'melissa',\n",
       " 'adelaide',\n",
       " 'amina',\n",
       " 'giselle',\n",
       " 'lena',\n",
       " 'camilla',\n",
       " 'miriam',\n",
       " 'millie',\n",
       " 'brynn',\n",
       " 'gabrielle',\n",
       " 'sage',\n",
       " 'annie',\n",
       " 'logan',\n",
       " 'lilliana',\n",
       " 'haven',\n",
       " 'jessica',\n",
       " 'kaia',\n",
       " 'magnolia',\n",
       " 'amira',\n",
       " 'adelynn',\n",
       " 'makenzie',\n",
       " 'stephanie',\n",
       " 'nina',\n",
       " 'phoebe',\n",
       " 'arielle',\n",
       " 'evie',\n",
       " 'lyric',\n",
       " 'alessandra',\n",
       " 'gabriela',\n",
       " 'paislee',\n",
       " 'raelyn',\n",
       " 'madilyn',\n",
       " 'paris',\n",
       " 'makenna',\n",
       " 'kinley',\n",
       " 'gracelyn',\n",
       " 'talia',\n",
       " 'maeve',\n",
       " 'rylie',\n",
       " 'kiara',\n",
       " 'evelynn',\n",
       " 'brinley',\n",
       " 'jacqueline',\n",
       " 'laura',\n",
       " 'gracelynn',\n",
       " 'lexi',\n",
       " 'ariah',\n",
       " 'fatima',\n",
       " 'jennifer',\n",
       " 'kehlani',\n",
       " 'alani',\n",
       " 'ariyah',\n",
       " 'luciana',\n",
       " 'allie',\n",
       " 'heidi',\n",
       " 'maci',\n",
       " 'phoenix',\n",
       " 'felicity',\n",
       " 'joy',\n",
       " 'kenzie',\n",
       " 'veronica',\n",
       " 'margot',\n",
       " 'addilyn',\n",
       " 'lana',\n",
       " 'cassidy',\n",
       " 'remington',\n",
       " 'saylor',\n",
       " 'ryan',\n",
       " 'keira',\n",
       " 'harlow',\n",
       " 'miranda',\n",
       " 'angel',\n",
       " 'amanda',\n",
       " 'daniella',\n",
       " 'royalty',\n",
       " 'gwendolyn',\n",
       " 'ophelia',\n",
       " 'heaven',\n",
       " 'jordan',\n",
       " 'madeleine',\n",
       " 'esmeralda',\n",
       " 'kira',\n",
       " 'miracle',\n",
       " 'elle',\n",
       " 'amari',\n",
       " 'danielle',\n",
       " 'daphne',\n",
       " 'willa',\n",
       " 'haley',\n",
       " 'gia',\n",
       " 'kaitlyn',\n",
       " 'oakley',\n",
       " 'kailani',\n",
       " 'winter',\n",
       " 'alicia',\n",
       " 'serena',\n",
       " 'nadia',\n",
       " 'aviana',\n",
       " 'demi',\n",
       " 'jada',\n",
       " 'braelynn',\n",
       " 'dylan',\n",
       " 'ainsley',\n",
       " 'alison',\n",
       " 'camryn',\n",
       " 'avianna',\n",
       " 'bianca',\n",
       " 'skyler',\n",
       " 'scarlet',\n",
       " 'maddison',\n",
       " 'nylah',\n",
       " 'sarai',\n",
       " 'regina',\n",
       " 'dahlia',\n",
       " 'nayeli',\n",
       " 'raven',\n",
       " 'helen',\n",
       " 'adrianna',\n",
       " 'averie',\n",
       " 'skye',\n",
       " 'kelsey',\n",
       " 'tatum',\n",
       " 'kensley',\n",
       " 'maliyah',\n",
       " 'erin',\n",
       " 'viviana',\n",
       " 'jenna',\n",
       " 'anaya',\n",
       " 'carolina',\n",
       " 'shelby',\n",
       " 'sabrina',\n",
       " 'mikayla',\n",
       " 'annalise',\n",
       " 'octavia',\n",
       " 'lennon',\n",
       " 'blair',\n",
       " 'carmen',\n",
       " 'yaretzi',\n",
       " 'kennedi',\n",
       " 'mabel',\n",
       " 'zariah',\n",
       " 'kyla',\n",
       " 'christina',\n",
       " 'selah',\n",
       " 'celeste',\n",
       " 'eve',\n",
       " 'mckinley',\n",
       " 'milani',\n",
       " 'frances',\n",
       " 'jimena',\n",
       " 'kylee',\n",
       " 'leighton',\n",
       " 'katie',\n",
       " 'aitana',\n",
       " 'kayleigh',\n",
       " 'sierra',\n",
       " 'kathryn',\n",
       " 'rosemary',\n",
       " 'jolene',\n",
       " 'alondra',\n",
       " 'elisa',\n",
       " 'helena',\n",
       " 'charleigh',\n",
       " 'hallie',\n",
       " 'lainey',\n",
       " 'avah',\n",
       " 'jazlyn',\n",
       " 'kamryn',\n",
       " 'mira',\n",
       " 'cheyenne',\n",
       " 'francesca',\n",
       " 'antonella',\n",
       " 'wren',\n",
       " 'chelsea',\n",
       " 'amber',\n",
       " 'emory',\n",
       " 'lorelei',\n",
       " 'nia',\n",
       " 'abby',\n",
       " 'april',\n",
       " 'emelia',\n",
       " 'carter',\n",
       " 'aylin',\n",
       " 'cataleya',\n",
       " 'bethany',\n",
       " 'marlee',\n",
       " 'carly',\n",
       " 'kaylani',\n",
       " 'emely',\n",
       " 'liana',\n",
       " 'madelynn',\n",
       " 'cadence',\n",
       " 'matilda',\n",
       " 'sylvia',\n",
       " 'myra',\n",
       " 'fernanda',\n",
       " 'oaklyn',\n",
       " 'elianna',\n",
       " 'hattie',\n",
       " 'dayana',\n",
       " 'kendra',\n",
       " 'maisie',\n",
       " 'malaysia',\n",
       " 'kara',\n",
       " 'katelyn',\n",
       " 'maia',\n",
       " 'celine',\n",
       " 'cameron',\n",
       " 'renata',\n",
       " 'jayleen',\n",
       " 'charli',\n",
       " 'emmalyn',\n",
       " 'holly',\n",
       " 'azalea',\n",
       " 'leona',\n",
       " 'alejandra',\n",
       " 'bristol',\n",
       " 'collins',\n",
       " 'imani',\n",
       " 'meadow',\n",
       " 'alexia',\n",
       " 'edith',\n",
       " 'kaydence',\n",
       " 'leslie',\n",
       " 'lilith',\n",
       " 'kora',\n",
       " 'aisha',\n",
       " 'meredith',\n",
       " 'danna',\n",
       " 'wynter',\n",
       " 'emberly',\n",
       " 'julieta',\n",
       " 'michaela',\n",
       " 'alayah',\n",
       " 'jemma',\n",
       " 'reign',\n",
       " 'colette',\n",
       " 'kaliyah',\n",
       " 'elliott',\n",
       " 'johanna',\n",
       " 'remy',\n",
       " 'sutton',\n",
       " 'emmy',\n",
       " 'virginia',\n",
       " 'briana',\n",
       " 'oaklynn',\n",
       " 'adelina',\n",
       " 'everlee',\n",
       " 'megan',\n",
       " 'angelica',\n",
       " 'justice',\n",
       " 'mariam',\n",
       " 'khaleesi',\n",
       " 'macie',\n",
       " 'karsyn',\n",
       " 'alanna',\n",
       " 'aleah',\n",
       " 'mae',\n",
       " 'mallory',\n",
       " 'esme',\n",
       " 'skyla',\n",
       " 'madilynn',\n",
       " 'charley',\n",
       " 'allyson',\n",
       " 'hanna',\n",
       " 'shiloh',\n",
       " 'henley',\n",
       " 'macy',\n",
       " 'maryam',\n",
       " 'ivanna',\n",
       " 'ashlynn',\n",
       " 'lorelai',\n",
       " 'amora',\n",
       " 'ashlyn',\n",
       " 'sasha',\n",
       " 'baylee',\n",
       " 'beatrice',\n",
       " 'itzel',\n",
       " 'priscilla',\n",
       " 'marie',\n",
       " 'jayda',\n",
       " 'liberty',\n",
       " 'rory',\n",
       " 'alessia',\n",
       " 'alaia',\n",
       " 'janelle',\n",
       " 'kalani',\n",
       " 'gloria',\n",
       " 'sloan',\n",
       " 'dorothy',\n",
       " 'greta',\n",
       " 'julie',\n",
       " 'zahra',\n",
       " 'savanna',\n",
       " 'annabella',\n",
       " 'poppy',\n",
       " 'amalia',\n",
       " 'zaylee',\n",
       " 'cecelia',\n",
       " 'coraline',\n",
       " 'kimber',\n",
       " 'emmie',\n",
       " 'anne',\n",
       " 'karina',\n",
       " 'kassidy',\n",
       " 'kynlee',\n",
       " 'monroe',\n",
       " 'anahi',\n",
       " 'jaliyah',\n",
       " 'jazmin',\n",
       " 'maren',\n",
       " 'monica',\n",
       " 'siena',\n",
       " 'marilyn',\n",
       " 'reyna',\n",
       " 'kyra',\n",
       " 'lilian',\n",
       " 'jamie',\n",
       " 'melany',\n",
       " 'alaya',\n",
       " 'ariya',\n",
       " 'kelly',\n",
       " 'rosie',\n",
       " 'adley',\n",
       " 'dream',\n",
       " 'jaylah',\n",
       " 'laurel',\n",
       " 'jazmine',\n",
       " 'mina',\n",
       " 'karla',\n",
       " 'bailee',\n",
       " 'aubrie',\n",
       " 'katalina',\n",
       " 'melina',\n",
       " 'harlee',\n",
       " 'elliot',\n",
       " 'hayley',\n",
       " 'elaine',\n",
       " 'karen',\n",
       " 'dallas',\n",
       " 'irene',\n",
       " 'lylah',\n",
       " 'ivory',\n",
       " 'chaya',\n",
       " 'rosa',\n",
       " 'aleena',\n",
       " 'braelyn',\n",
       " 'nola',\n",
       " 'alma',\n",
       " 'leyla',\n",
       " 'pearl',\n",
       " 'addyson',\n",
       " 'roselyn',\n",
       " 'lacey',\n",
       " 'lennox',\n",
       " 'reina',\n",
       " 'aurelia',\n",
       " 'noa',\n",
       " 'janiyah',\n",
       " 'jessie',\n",
       " 'madisyn',\n",
       " 'saige',\n",
       " 'alia',\n",
       " 'tiana',\n",
       " 'astrid',\n",
       " 'cassandra',\n",
       " 'kyleigh',\n",
       " 'romina',\n",
       " 'stevie',\n",
       " 'haylee',\n",
       " 'zelda',\n",
       " 'lillie',\n",
       " 'aileen',\n",
       " 'brylee',\n",
       " 'eileen',\n",
       " 'yara',\n",
       " 'ensley',\n",
       " 'lauryn',\n",
       " 'giuliana',\n",
       " 'livia',\n",
       " 'anya',\n",
       " 'mikaela',\n",
       " 'palmer',\n",
       " 'lyra',\n",
       " 'mara',\n",
       " 'marina',\n",
       " 'kailey',\n",
       " 'liv',\n",
       " 'clementine',\n",
       " 'kenna',\n",
       " 'briar',\n",
       " 'emerie',\n",
       " 'galilea',\n",
       " 'tiffany',\n",
       " 'bonnie',\n",
       " 'elyse',\n",
       " 'cynthia',\n",
       " 'frida',\n",
       " 'kinslee',\n",
       " 'tatiana',\n",
       " 'joelle',\n",
       " 'armani',\n",
       " 'jolie',\n",
       " 'nalani',\n",
       " 'rayna',\n",
       " 'yareli',\n",
       " 'meghan',\n",
       " 'rebekah',\n",
       " 'addilynn',\n",
       " 'faye',\n",
       " 'zariyah',\n",
       " 'lea',\n",
       " 'aliza',\n",
       " 'julissa',\n",
       " 'lilyana',\n",
       " 'anika',\n",
       " 'kairi',\n",
       " 'aniya',\n",
       " 'noemi',\n",
       " 'angie',\n",
       " 'crystal',\n",
       " 'bridget',\n",
       " 'ari',\n",
       " 'davina',\n",
       " 'amelie',\n",
       " 'amirah',\n",
       " 'annika',\n",
       " 'elora',\n",
       " 'xiomara',\n",
       " 'linda',\n",
       " 'hana',\n",
       " 'laney',\n",
       " 'mercy',\n",
       " 'hadassah',\n",
       " 'madalyn',\n",
       " 'louisa',\n",
       " 'simone',\n",
       " 'kori',\n",
       " 'jillian',\n",
       " 'alena',\n",
       " 'malaya',\n",
       " 'miley',\n",
       " 'milan',\n",
       " 'sariyah',\n",
       " 'malani',\n",
       " 'clarissa',\n",
       " 'nala',\n",
       " 'princess',\n",
       " 'amani',\n",
       " 'analia',\n",
       " 'estella',\n",
       " 'milana',\n",
       " 'aya',\n",
       " 'chana',\n",
       " 'jayde',\n",
       " 'tenley',\n",
       " 'zaria',\n",
       " 'itzayana',\n",
       " 'penny',\n",
       " 'ailani',\n",
       " 'lara',\n",
       " 'aubriella',\n",
       " 'clare',\n",
       " 'lina',\n",
       " 'rhea',\n",
       " 'bria',\n",
       " 'thalia',\n",
       " 'keyla',\n",
       " 'haisley',\n",
       " 'ryann',\n",
       " 'addisyn',\n",
       " 'amaia',\n",
       " 'chanel',\n",
       " 'ellen',\n",
       " 'harmoni',\n",
       " 'aliana',\n",
       " 'tinsley',\n",
       " 'landry',\n",
       " 'paisleigh',\n",
       " 'lexie',\n",
       " 'myah',\n",
       " 'rylan',\n",
       " 'deborah',\n",
       " 'emilee',\n",
       " 'laylah',\n",
       " 'novalee',\n",
       " 'ellis',\n",
       " 'emmeline',\n",
       " 'avalynn',\n",
       " 'hadlee',\n",
       " 'legacy',\n",
       " 'braylee',\n",
       " 'elisabeth',\n",
       " 'kaylie',\n",
       " 'ansley',\n",
       " 'dior',\n",
       " 'paula',\n",
       " 'belen',\n",
       " 'corinne',\n",
       " 'maleah',\n",
       " 'martha',\n",
       " 'teresa',\n",
       " 'salma',\n",
       " 'louise',\n",
       " 'averi',\n",
       " 'lilianna',\n",
       " 'amiya',\n",
       " 'milena',\n",
       " 'royal',\n",
       " 'aubrielle',\n",
       " 'calliope',\n",
       " 'frankie',\n",
       " 'natasha',\n",
       " 'kamilah',\n",
       " 'meilani',\n",
       " 'raina',\n",
       " 'amayah',\n",
       " 'lailah',\n",
       " 'rayne',\n",
       " 'zaniyah',\n",
       " 'isabela',\n",
       " 'nathalie',\n",
       " 'miah',\n",
       " 'opal',\n",
       " 'kenia',\n",
       " 'azariah',\n",
       " 'hunter',\n",
       " 'tori',\n",
       " 'andi',\n",
       " 'keily',\n",
       " 'leanna',\n",
       " 'scarlette',\n",
       " 'jaelyn',\n",
       " 'saoirse',\n",
       " 'selene',\n",
       " 'dalary',\n",
       " 'lindsey',\n",
       " 'marianna',\n",
       " 'ramona',\n",
       " 'estelle',\n",
       " 'giovanna',\n",
       " 'holland',\n",
       " 'nancy',\n",
       " 'emmalynn',\n",
       " 'mylah',\n",
       " 'rosalee',\n",
       " 'sariah',\n",
       " 'zoie',\n",
       " 'blaire',\n",
       " 'lyanna',\n",
       " 'maxine',\n",
       " 'anais',\n",
       " 'dana',\n",
       " 'judith',\n",
       " 'kiera',\n",
       " 'jaelynn',\n",
       " 'noor',\n",
       " 'kai',\n",
       " 'adalee',\n",
       " 'oaklee',\n",
       " 'amaris',\n",
       " 'jaycee',\n",
       " 'belle',\n",
       " 'carolyn',\n",
       " 'della',\n",
       " 'karter',\n",
       " 'sky',\n",
       " 'treasure',\n",
       " 'vienna',\n",
       " 'jewel',\n",
       " 'rivka',\n",
       " 'rosalyn',\n",
       " 'alannah',\n",
       " 'ellianna',\n",
       " 'sunny',\n",
       " 'claudia',\n",
       " 'cara',\n",
       " 'hailee',\n",
       " 'estrella',\n",
       " 'harleigh',\n",
       " 'zhavia',\n",
       " 'alianna',\n",
       " 'brittany',\n",
       " 'jaylene',\n",
       " 'journi',\n",
       " 'marissa',\n",
       " 'mavis',\n",
       " 'iliana',\n",
       " 'jurnee',\n",
       " 'aislinn',\n",
       " 'alyson',\n",
       " 'elsa',\n",
       " 'kamiyah',\n",
       " 'kiana',\n",
       " 'lisa',\n",
       " 'arlette',\n",
       " 'kadence',\n",
       " 'kathleen',\n",
       " 'halle',\n",
       " 'erika',\n",
       " 'sylvie',\n",
       " 'adele',\n",
       " 'erica',\n",
       " 'veda',\n",
       " 'whitney',\n",
       " 'bexley',\n",
       " 'emmaline',\n",
       " 'guadalupe',\n",
       " 'august',\n",
       " 'brynleigh',\n",
       " 'gwen',\n",
       " 'promise',\n",
       " 'alisson',\n",
       " 'india',\n",
       " 'madalynn',\n",
       " 'paloma',\n",
       " 'patricia',\n",
       " 'samira',\n",
       " 'aliya',\n",
       " 'casey',\n",
       " 'jazlynn',\n",
       " 'paulina',\n",
       " 'dulce',\n",
       " 'kallie',\n",
       " 'perla',\n",
       " 'adrienne',\n",
       " 'alora',\n",
       " 'nataly',\n",
       " 'ayleen',\n",
       " 'christine',\n",
       " 'kaiya',\n",
       " 'ariadne',\n",
       " 'karlee',\n",
       " 'barbara',\n",
       " 'lillianna',\n",
       " 'raquel',\n",
       " 'saniyah',\n",
       " 'yamileth',\n",
       " 'arely',\n",
       " 'celia',\n",
       " 'heavenly',\n",
       " 'kaylin',\n",
       " 'marisol',\n",
       " 'marleigh',\n",
       " 'avalyn',\n",
       " 'berkley',\n",
       " 'kataleya',\n",
       " 'zainab',\n",
       " 'dani',\n",
       " 'egypt',\n",
       " 'joyce',\n",
       " 'kenley',\n",
       " 'annabel',\n",
       " 'kaelyn',\n",
       " 'etta',\n",
       " 'hadleigh',\n",
       " 'joselyn',\n",
       " 'luella',\n",
       " 'jaylee',\n",
       " 'zola',\n",
       " 'alisha',\n",
       " 'ezra',\n",
       " 'queen',\n",
       " 'amia',\n",
       " 'annalee',\n",
       " 'bellamy',\n",
       " 'paola',\n",
       " 'tinley',\n",
       " 'violeta',\n",
       " 'jenesis',\n",
       " 'arden',\n",
       " 'giana',\n",
       " 'wendy',\n",
       " 'ellison',\n",
       " 'florence',\n",
       " 'margo',\n",
       " 'naya',\n",
       " 'robin',\n",
       " 'sandra',\n",
       " 'scout',\n",
       " 'waverly',\n",
       " 'janessa',\n",
       " 'jayden',\n",
       " 'micah',\n",
       " 'novah',\n",
       " 'zora',\n",
       " 'ann',\n",
       " 'jana',\n",
       " 'taliyah',\n",
       " 'vada',\n",
       " 'giavanna',\n",
       " 'ingrid',\n",
       " 'valery',\n",
       " 'azaria',\n",
       " 'emmarie',\n",
       " 'esperanza',\n",
       " 'kailyn',\n",
       " 'aiyana',\n",
       " 'keilani',\n",
       " 'austyn',\n",
       " 'whitley',\n",
       " 'elina',\n",
       " 'kimora',\n",
       " 'maliah',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:31:05.302637Z",
     "start_time": "2024-07-23T13:31:05.298934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ],
   "id": "d1cfc735e2a0b2be",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:00:47.548947Z",
     "start_time": "2024-07-23T11:00:47.541328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ],
   "id": "c1611f765791a444",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:00:52.339616Z",
     "start_time": "2024-07-23T11:00:52.336270Z"
    }
   },
   "cell_type": "code",
   "source": "stoi",
   "id": "4478ee5af62b04a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:45:50.087387Z",
     "start_time": "2024-07-23T13:45:49.945072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create the training set of trigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    ix3 = stoi[ch3]\n",
    "    xs.append((ix1, ix2))\n",
    "    ys.append(ix3)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = len(xs)"
   ],
   "id": "ae810f0efe0f9020",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:56:46.765699Z",
     "start_time": "2024-07-23T13:56:46.762561Z"
    }
   },
   "cell_type": "code",
   "source": "xs",
   "id": "df1078d84d514226",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5],\n",
       "        [ 5, 13],\n",
       "        [13, 13],\n",
       "        ...,\n",
       "        [26, 25],\n",
       "        [25, 26],\n",
       "        [26, 24]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:45:51.964780Z",
     "start_time": "2024-07-23T13:45:51.961432Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"number of examples: {num}\")",
   "id": "e76385fcf0e5bb95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples: 196113\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:50:34.588192Z",
     "start_time": "2024-07-23T13:50:34.585165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ],
   "id": "8bb85332897c8e4e",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:57:24.538228Z",
     "start_time": "2024-07-23T13:57:24.522722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float().view(-1, 27*2)\n",
    "xenc"
   ],
   "id": "5740bb3369cc7b98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:56:16.434804Z",
     "start_time": "2024-07-23T13:56:12.638497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27).float().view(-1, 27*2)\n",
    "  logits = xenc @ W\n",
    "  counts = logits.exp()\n",
    "  probs = counts / counts.sum(1, keepdims=True)\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean() # the + ... is regularization\n",
    "  print(loss.item())\n",
    "  \n",
    "  #backward pass\n",
    "  W.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  #update\n",
    "  W.data += -50 * W.grad"
   ],
   "id": "1a14b01efd19708b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2593140602111816\n",
      "2.2592546939849854\n",
      "2.2591967582702637\n",
      "2.259139060974121\n",
      "2.259082317352295\n",
      "2.259025812149048\n",
      "2.258970260620117\n",
      "2.258915424346924\n",
      "2.2588608264923096\n",
      "2.2588071823120117\n",
      "2.258754253387451\n",
      "2.258701801300049\n",
      "2.258650064468384\n",
      "2.258598804473877\n",
      "2.25854754447937\n",
      "2.258497714996338\n",
      "2.2584481239318848\n",
      "2.25839900970459\n",
      "2.258350372314453\n",
      "2.2583024501800537\n",
      "2.2582550048828125\n",
      "2.2582080364227295\n",
      "2.2581615447998047\n",
      "2.258115768432617\n",
      "2.258070230484009\n",
      "2.2580254077911377\n",
      "2.2579808235168457\n",
      "2.257936716079712\n",
      "2.2578933238983154\n",
      "2.257850170135498\n",
      "2.257807731628418\n",
      "2.257765531539917\n",
      "2.257723808288574\n",
      "2.2576828002929688\n",
      "2.2576417922973633\n",
      "2.257601499557495\n",
      "2.257561445236206\n",
      "2.257521867752075\n",
      "2.2574825286865234\n",
      "2.25744366645813\n",
      "2.2574055194854736\n",
      "2.2573676109313965\n",
      "2.2573301792144775\n",
      "2.2572929859161377\n",
      "2.257255792617798\n",
      "2.2572197914123535\n",
      "2.25718355178833\n",
      "2.257148027420044\n",
      "2.257112741470337\n",
      "2.25707745552063\n",
      "2.2570431232452393\n",
      "2.2570087909698486\n",
      "2.256974935531616\n",
      "2.256941318511963\n",
      "2.2569081783294678\n",
      "2.2568750381469727\n",
      "2.256842851638794\n",
      "2.256810188293457\n",
      "2.2567784786224365\n",
      "2.256746530532837\n",
      "2.2567152976989746\n",
      "2.2566843032836914\n",
      "2.2566535472869873\n",
      "2.2566232681274414\n",
      "2.2565927505493164\n",
      "2.2565629482269287\n",
      "2.25653338432312\n",
      "2.2565040588378906\n",
      "2.2564752101898193\n",
      "2.256446361541748\n",
      "2.256417989730835\n",
      "2.256389856338501\n",
      "2.256362199783325\n",
      "2.256334066390991\n",
      "2.2563068866729736\n",
      "2.256279706954956\n",
      "2.2562530040740967\n",
      "2.2562263011932373\n",
      "2.256199598312378\n",
      "2.256174087524414\n",
      "2.256147861480713\n",
      "2.25612211227417\n",
      "2.256096839904785\n",
      "2.2560715675354004\n",
      "2.256046772003174\n",
      "2.2560219764709473\n",
      "2.255997657775879\n",
      "2.2559733390808105\n",
      "2.2559492588043213\n",
      "2.255925416946411\n",
      "2.255901575088501\n",
      "2.2558786869049072\n",
      "2.255855083465576\n",
      "2.2558324337005615\n",
      "2.2558095455169678\n",
      "2.255786895751953\n",
      "2.2557647228240967\n",
      "2.255742311477661\n",
      "2.255720615386963\n",
      "2.2556986808776855\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:59:09.878053Z",
     "start_time": "2024-07-23T13:59:09.876444Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "97328ac32b954db5",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T14:02:04.390026Z",
     "start_time": "2024-07-23T14:02:04.381747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    ix1 = 0\n",
    "    ix2 = torch.multinomial(torch.ones(27) / 27, 1, replacement=True, generator=g).item()  # Randomly choose the second character\n",
    "    out = [itos[ix2]]\n",
    "    while True:\n",
    "      xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float().view(-1, 27*2)\n",
    "      logits = xenc @ W\n",
    "      counts = logits.exp()\n",
    "      p = counts / counts.sum(1, keepdims=True)\n",
    "      \n",
    "      ix1 = ix2 \n",
    "      ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "      out.append(itos[ix2])\n",
    "      if ix2 == 0:\n",
    "        break\n",
    "            \n",
    "    print(\"\".join(out))"
   ],
   "id": "85db1b72483bf5b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexze.\n",
      "zomakurailaziaydamellimittain.\n",
      "lusan.\n",
      "ka.\n",
      "da.\n",
      "samiyaubrtthrigotai.\n",
      "iolielliaugie.\n",
      "teda.\n",
      "kaleyla.\n",
      "sade.\n",
      "enkavirny.\n",
      "fobspih.\n",
      "ciden.\n",
      "tahlasu.\n",
      "dydr.\n",
      "breegl.\n",
      "peig.\n",
      "iatta.\n",
      "ra.\n",
      "dinne.\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# E02 - Dataset split up",
   "id": "3633879348cbf774"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T14:56:48.293546Z",
     "start_time": "2024-07-23T14:56:48.282149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "train_size = int(0.8 * len(words))\n",
    "dev_size = int(0.1 * len(words))\n",
    "test_size = int(len(words) - train_size - dev_size)\n",
    "\n",
    "train_set, dev_set, test_set = random_split(words, [train_size, dev_size, test_size], generator=g)"
   ],
   "id": "522afd878633529e",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T15:23:12.102851Z",
     "start_time": "2024-07-23T15:23:11.965935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create the training set of trigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in train_set:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    ix3 = stoi[ch3]\n",
    "    xs.append((ix1, ix2))\n",
    "    ys.append(ix3)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = len(xs)\n",
    "\n",
    "def random_weights_initialize():\n",
    "  # randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "  g = torch.Generator().manual_seed(2147483647)\n",
    "  W = torch.randn((27*2, 27), generator=g, requires_grad=True)\n",
    "  return W"
   ],
   "id": "316b56e5d1f214ea",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T15:35:58.673594Z",
     "start_time": "2024-07-23T15:35:58.669242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gradient descent\n",
    "def gradient_descent(W, reg_fac):\n",
    "  for _ in range(100):\n",
    "    \n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float().view(-1, 27*2)\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + reg_fac*(W**2).mean() # the + ... is regularization\n",
    "    #print(loss.item())\n",
    "    \n",
    "    #backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    W.data += -50 * W.grad\n",
    "      \n",
    "  return loss.item() "
   ],
   "id": "45f76ad58f62afdd",
   "outputs": [],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T15:23:14.532130Z",
     "start_time": "2024-07-23T15:23:14.494862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dev_eval_x, dev_eval_y = [], []\n",
    "\n",
    "for w in dev_set:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    ix3 = stoi[ch3]\n",
    "    dev_eval_x.append((ix1, ix2))\n",
    "    dev_eval_y.append(ix3)\n",
    "      \n",
    "dev_eval_x = torch.tensor(dev_eval_x)\n",
    "dev_eval_y = torch.tensor(dev_eval_y)\n",
    "dev_num = len(dev_eval_x)\n",
    "    \n",
    "test_eval_x, test_eval_y = [], []\n",
    "\n",
    "for w in test_set:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    ix3 = stoi[ch3]\n",
    "    test_eval_x.append((ix1, ix2))\n",
    "    test_eval_y.append(ix3)\n",
    "      \n",
    "test_eval_x = torch.tensor(test_eval_x)\n",
    "test_eval_y = torch.tensor(test_eval_y)\n",
    "test_num = len(test_eval_x)"
   ],
   "id": "2ee617f320ab65c0",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T15:52:48.095207Z",
     "start_time": "2024-07-23T15:52:48.086918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_loss(xs, ys, num, regularization_factor):\n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27).float().view(-1, 27*2)\n",
    "  logits = xenc @ W\n",
    "  counts = logits.exp()\n",
    "  probs = counts / counts.sum(1, keepdims=True)\n",
    "  loss = -probs[torch.arange(num), ys].log().mean()# + regularization_factor*(W**2).mean()\n",
    "  return loss.item()"
   ],
   "id": "ab8b67c5d41ae0e6",
   "outputs": [],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T15:23:16.663124Z",
     "start_time": "2024-07-23T15:23:16.640051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(get_loss(dev_eval_x, dev_eval_y, dev_num, 0.01))\n",
    "print(get_loss(test_eval_x, test_eval_y, test_num, 0.01))"
   ],
   "id": "e3e2cd6c72fe22cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2535791397094727\n",
      "2.256826877593994\n"
     ]
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# E03 - Tuning regularization using DevSet",
   "id": "38ead05c61b11aa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:04:08.573292Z",
     "start_time": "2024-07-23T15:52:49.889611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_loss = (10000000, 0)\n",
    "for reg_fac in list(torch.arange(0, 0.05, 0.005)) + list(torch.arange(0.05, 0.5, 0.05)):\n",
    "  W = random_weights_initialize()\n",
    "  train_loss = gradient_descent(W, reg_fac)\n",
    "  dev_loss = get_loss(dev_eval_x, dev_eval_y, dev_num, reg_fac)\n",
    "  print(f\"For a Regularization factor of: {reg_fac:.3f}\\nThe train loss is: {train_loss:.4f}\\nThe Dev loss is: {dev_loss:.4f}\\n-=-=-=-=-=-=-=-=-=-=-=-\")\n",
    "  if dev_loss < best_loss[0]:\n",
    "    best_loss = (dev_loss, reg_fac)\n",
    "      \n",
    "print(f\"The best Dev loss is: {best_loss[0]:.4f} for a regularization factor of: {best_loss[1]:.3f}\")"
   ],
   "id": "97ea9fc0296ba65c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a Regularization factor of: 0.000\n",
      "The train loss is: 2.2395\n",
      "The Dev loss is: 2.2341\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.005\n",
      "The train loss is: 2.2475\n",
      "The Dev loss is: 2.2347\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.010\n",
      "The train loss is: 2.2540\n",
      "The Dev loss is: 2.2357\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.015\n",
      "The train loss is: 2.2597\n",
      "The Dev loss is: 2.2369\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.020\n",
      "The train loss is: 2.2648\n",
      "The Dev loss is: 2.2382\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.025\n",
      "The train loss is: 2.2696\n",
      "The Dev loss is: 2.2395\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.030\n",
      "The train loss is: 2.2740\n",
      "The Dev loss is: 2.2409\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.035\n",
      "The train loss is: 2.2782\n",
      "The Dev loss is: 2.2422\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.040\n",
      "The train loss is: 2.2822\n",
      "The Dev loss is: 2.2436\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.045\n",
      "The train loss is: 2.2860\n",
      "The Dev loss is: 2.2449\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.050\n",
      "The train loss is: 2.2897\n",
      "The Dev loss is: 2.2462\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.100\n",
      "The train loss is: 2.3204\n",
      "The Dev loss is: 2.2584\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.150\n",
      "The train loss is: 2.3447\n",
      "The Dev loss is: 2.2693\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.200\n",
      "The train loss is: 2.3654\n",
      "The Dev loss is: 2.2792\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.250\n",
      "The train loss is: 2.3836\n",
      "The Dev loss is: 2.2883\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.300\n",
      "The train loss is: 2.4000\n",
      "The Dev loss is: 2.2969\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.350\n",
      "The train loss is: 2.4150\n",
      "The Dev loss is: 2.3050\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.400\n",
      "The train loss is: 2.4288\n",
      "The Dev loss is: 2.3126\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "For a Regularization factor of: 0.450\n",
      "The train loss is: 2.4417\n",
      "The Dev loss is: 2.3200\n",
      "-=-=-=-=-=-=-=-=-=-=-=-\n",
      "The best Dev loss is: 2.2341 for a regularization factor of: 0.000\n"
     ]
    }
   ],
   "execution_count": 214
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1134d6917d195f17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
